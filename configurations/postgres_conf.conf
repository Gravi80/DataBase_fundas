http://www.dbdude.com/postgresql/postgresqlperformance.php

pg_hba.conf => for security

postgresql.conf => for configuration


run  "pg_ctl reload" after changing postgres configurations


Viewing the current settings
==============================
show all, show <setting> will show you the current value of the setting.

Ravi=#	show all
Ravi=#	show log_directory;

Watch out for session specific changes

select * from pg_settings; 
will label session specific changes as locally modified.





shared buffers
checkpoint segments
autovacuum
synchronous commit + wal writer delay
wal buffers
checkpoint completion target
wal sync method



checkpoint_completion_target = 0.5
checkpoint_segments = 32
checkpoint_timeout = 30min
cpu_index_tuple_cost = 0.005
cpu_operator_cost = 0.0025
cpu_tuple_cost = 0.01
default_statistics_target = 500 (evaluated 100 to 10000 analyse after each)
effective_cache_size = 288GB
enable_seqscan = off
from_collapse_limit = 8
geqo = off
join_collapse_limit = 8
random_page_cost = 1.0
seq_page_cost = 1.0
shared_buffers = 96GB
work_mem = 64MB


A setting of random_page_cost = 1.0 only makes sense if random access is actually as fast as sequential access, which is only true if your DB resides in RAM entirely.
Try at least 1.1, probably more. Run tests to find the sweet spot in your setup.


Extremely low settings for random_page_cost favors index scans over bitmap index scans. 




SET enable_bitmapscan = off;








Generally located inside data directory.

You can also include your parameters in a different parameter file and 
use "include directive" to include those files in postgresql.conf

You can make changes into the configuration not just at instane level but
at database level using ALTER DATABASE command.
If you have got multiple database in ur cluster, u can use parameter value according  to the nature of that database.


You can also use ALTER USER command to set these parameter for a user.

You can change parameter value at session/transaction level, but not all parameters
can be changed at session level, Ex: Shared memory, shared buffers, WAL buffers.
These parameters can only be changed inside postgresql.conf or on startup.



MEMORY PARAMETERS
==================

shared_buffers
---------------
Default size is really small - 32 MB

	A Good Value
	------------
	=> 15%-30% of total available RAM on a dedicated DB server
	=> On 32-bit setup a value above 2GB is not practical, due to some inner limitations with 32-bits OS.

On v9.2 and earlier you need to set SHMMAX parameter at OS kernel level as well before you can increase
shared_buffer.



work_mem
---------
This is sorting memory, this is the allocation in your shared memory where sorting happens.

=> A higher value improves query performance faster with in-memort sort,
	
=> You can log [ log_temp_files ] your temp files creation, in which case if sorts are going to
	disk they will be logged.
	you can also check that by doing an Explain plan [ e.g Sort Method: external merge Disk: XKb ], which tells
	 how much space was used on disk for this sorting.


	A Good Value
	-------------
	You should either try to set this to a high enough value which enables in-memory sort, in which case Quick Sort
	will be used.
	but in certain cases Quik Sort can use lot of memory and these cases you can set it to atleast to the amount
	of memory which is been taken on disk for an external sort.


This is 'per sorting operation', if a statement has multiple sort requirements those many sorting space
will be allocated.
If your statement invloves 8 tables and does a sort on 8 tables, 8 block of work_mem would be allocated.
so if work_mem=50Mb , you will end up spending somewhere around 400MB just for one statement execution.
And If you have 10 such statments executing u will end up spending 4GB of ur memory.

So, it not a very good idea to set a high value at the instance level, instead u can save a moderate value which 
serves most of ur statements at instance level and then change this value @ Database/User/Transaction/Session level




temp_buffer
-----------
The memory segement used for caching temporary tables, can be changed at the session level.
Remember to change it before you create you first temporary table.


This cache area will be used only if you r using temporary tables.




maintenance_work_mem
---------------------
Hepls improve the performance of maintenance operations( DDL statement execution ) e.g.
-VACUUM , CREATE INDEX, ALTER TABLE AND FOREIGN KEY

	A Good value
	------------
	 - should be large enough to hold your table for re-indexing or creation of indexes or vacuuming operations.
	 	on a 64Gb of RAM , 2GB for maintenance_work_mem could be safe.

A session can do only one maintenance operation at a time.
Parallel threads for autovacuum ( max_autovacuum_worker ) , each of them will consume one slot of maintenance_work_mem.






QUERY PLANNER PARAMETERS
=========================	 	

These parameters just an input to your optimizer , they help the optimizer decide the best plan.

 These parameters do not
 	- decide the actual performance
 	- define disk speed
 	- allocate memory or disk space



random_page_cost
-----------------
Cost of Accessing a random page on your disk.
This parameter does not define how fast postgres 'will' access random pages, defines how fast postgres
'can expect' the request for random pages to be fulfilled.

Default - 4.0

A larger value means that your index scans are going to be more costly bcz index scan needs random access of pages.
If you set this to lesser value optimizer would be pushed to choose an index scan over a table scan.

	Good Value:
	-----------
	- for most of the mordern disk 2.0 or 3.0
	- For flash disk / Solid State Disks you can set it to 1.1/1.2 or 1.5 or 1.8


If you see that you don't have too many index scans and your optimiser is choosing more table scans
, the first thing you should look at is 'effective_cache_size'.



sequential_page_cost
---------------------
Defines how fast your postgres can expect request for sequential pages to be fulfilled, which means
how fast tables can be scanned on there own.

Default- 1.0
	
	Good Value :
	------------
	- for faster disk(SSD) set this to 0.8 or 0.9


Always keep them lower then random_page_cost




effective_cache_size
---------------------	
Memory available to OS for File System cache.

Postgresql relies a lot on OS File System Caching.
This parameter helps optimiser how much amount of memory is available for caching the files and
this of great importance where optizer is considering index scans unless your pages can fit into 
the file system cache ur optimizer may not choose index scan.

In that case the reason is your effective_cache_size is not large enough , it is not that your actual
Cache allocation is smaller bcz that is defined / decided by the OS file system.
But it is just that you have not indicated in a proper way to ur postgresql process.


DEFAULT- 128MB

	Good Value :
	------------
	- 50%-80% of your RAM on a dedicated DB server
	- On Shared Server you can look at OS statistics by using ( Free + cached memory )

It is not an allocation of memory, it's not like shared buffer(something you allocate memory to postgresql).
A higher value is more likely to promote index scans.	






enable_* parameters
--------------------
There are some 'enable_* parameters', you can change these parameters at instance/session level.

These are used to tell optimiser whether you want to include particular optimizations techniques or not.
	- Index utilization : Index only scans , Index scans, Bitmap scans
	- Joins : merge join, nested table loop join, hash join
	Like : whether u want to use index only scans or not, if you set index_only_scan=off 
		   index only scan would not be used.

Always wise to leave them to default.

Try To Change them a specific query level not at instance level.





http://www.dbdude.com/postgresql/postgresqlperformance.php




