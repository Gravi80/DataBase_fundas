http://www.databasesoup.com/2012/09/freezing-your-tuples-off-part-1.html

A Freeze vacuum must scan and clean every single page so when vacuum is freezing if it can't acquire the CleanUp lock it will sit and wait and that can cuase other problems.
Because it is sitting for the cleanup lock any body else who want to access that page then have to wait and sit behind the vacuum.

This is changed in 9.1/9.2
So if a vaccum couldn't acquire a cleanup lock it would not sit there.



Transactions Ids(XIDs) and Multi Transaction Ids(MXIDs) , the way those are implemented is it's basically a circular counter.
starts at 2 and starts increasing and when it hits 2^31 , all the sudden 2 is no longer a transaction in the past and becomes the transaction in the future.
So, the problem is if you have rows which says oh i was created by transaction no. 2 and all of sudden you get to transaction 2^31+2 now that will become invisible bcz now the database is thinkig
Ohh this row is actually created by a transaction which is in future and it won't show it to you.

So, the way the system works around this/ handle this is as the transaction count increases eventually it has to go through and find all transaction Ids in all tables that are older and replace them with the special value that indicates that this row is visible to every body untill someone deletes it.

This Process is Known as freezing and has to be done both for XIDd and MXIDs.


If you don't handle Freezing correctly eventually the database will stop allowing you to create new transaction.


If You have very Extremely high rates of update transactions, you do lot of FOR SHARE LOCK bcz it will always generate a Multi Transaction Ids , or lot of concurrent FK checks happening you can run into problems of been able to freeze ur data.


to see the counter -> for transaction there is function get_current_snapshot() which will show u ur current XIDs.

txid.current
dat_frozen_xid -> tells you oldest non frozen transaction ID in each database.





You can see how close you are to autovacuum freeze anywhere with this query:
============================================================================
select max(age(datfrozenxid)) from pg_database;


However, you don't generally really care about that; what you care about is "how close am I to forced autovacuum freeze on a large table?"  Here's that:
======================================

SELECT relname, age(relfrozenxid) as xid_age, 
    pg_size_pretty(pg_table_size(oid)) as table_size
FROM pg_class 
WHERE relkind = 'r' and pg_table_size(oid) > 1073741824
ORDER BY age(relfrozenxid) DESC LIMIT 20;


More specifically, that says "give me the top 20 tables over 1GB, sorted by the age of their oldest XID".  Results look something like this:

        relname         |  xid_age  | table_size 
------------------------+-----------+------------
 postgres_log           | 199785216 | 12 GB
 statements             |   4551790 | 1271 MB
 normal_statement_times |        31 | 12 GB


  We see that postgres_log is at an XID age of 199 million, which is awfully close to the default autovacuum_freeze_max_age of 200 million.  And having autovac decide to read and rewrite an entire 12GB table, possibly at peak usage times, can cause unexpected poor application performance. 


 One thing we can do is raise autovacuum_freeze_max_age.  The default, 200m, is very conservative; it's only 10% of our shut-down-the-database threshold.  On high-transaction-volume databases, I generally raise it to 1 billion, which is still only the 50% mark.

 However, that's just putting off the problem.  What we should do is manually freeze the table at at time which is convenient for the application, i.e. during a low activity period or a scheduled downtime.  Then we run:


 VACUUM FREEZE postgres_log; 


 